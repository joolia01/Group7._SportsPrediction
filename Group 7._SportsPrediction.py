# -*- coding: utf-8 -*-
"""Group 7._SportsPrediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_Fw3zW9UtNenqYSeW9MgM3Jbe2hh-tFh

:***In this project, you are tasked to build a model/models that predict a player's overall rating given the player's profile.***
"""

#Mounting
from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.model_selection import cross_val_score
from xgboost import XGBRegressor
from sklearn.ensemble import VotingRegressor
from sklearn.metrics import accuracy_score
from sklearn.metrics import mean_squared_error
import pickle

import sklearn
sklearn.__version__

"""***Data Preprocessing***"""

#The name of my dataframe is 'fifa_df'.
fifa_df = pd.read_csv('/content/drive/My Drive/Introduction_to_AI_Mid_Semester_Project/players_21.csv')
fifa_df.info()
fifa_df.describe()
fifa_df.head()

#This code will generate a table displaying the column names, their non-null counts, and data types
non_null_counts = fifa_df.count()
data_types = fifa_df.dtypes

data_info = pd.DataFrame({'Column': non_null_counts.index, 'Non-Null Count': non_null_counts.values, 'Dtype': data_types.values})
data_info = data_info.reset_index(drop=True)

data_info_str = data_info.to_string()
print(data_info_str)

#This code will give a list of the column names in the DataFrame fifa_df that have the 'object' data type.
print("object columns")
object_columns = fifa_df.select_dtypes(include=['object']).columns
print(object_columns)

#This code will give a list of the column names in the DataFrame fifa_df that have the 'int' data type.
print("int columns")
int_columns = fifa_df.select_dtypes(include=['int64']).columns
print(int_columns)

#This code will give a list of the column names in the DataFrame fifa_df that have the 'float' data type.
print("float columns")
float_columns = fifa_df.select_dtypes(include=['float64']).columns
print(float_columns)

#Dropping features that cannot predicate a player's overall rating
#Store them  first
useless_features = [
       'player_url', 'short_name', 'long_name', 'player_positions', 'dob', 'league_name', 'club_position', 'club_loaned_from',
       'club_joined', 'nationality_name', 'nation_position', 'real_face', 'player_tags','player_face_url', 'club_logo_url',
       'club_flag_url', 'nation_logo_url', 'nation_flag_url', 'sofifa_id',  'nationality_id','club_team_id','club_jersey_number',
       'club_contract_valid_until', 'nation_team_id',
       'nation_jersey_number', 'release_clause_eur']

useless_features_dataframe = fifa_df[useless_features].copy()

fifa_df = fifa_df.drop(['player_url', 'short_name', 'long_name', 'player_positions', 'dob', 'league_name', 'club_position', 'club_loaned_from',
       'club_joined', 'nationality_name', 'nation_position', 'real_face', 'player_tags','player_face_url', 'club_logo_url',
       'club_flag_url', 'nation_logo_url', 'nation_flag_url', 'sofifa_id',  'nationality_id','club_team_id','club_jersey_number',
       'club_contract_valid_until', 'nation_team_id',
       'nation_jersey_number', 'release_clause_eur'], axis=1)

#Finding the percentage of missing values in each column
percentage_of_missing_values_per_column= fifa_df.isnull().sum()/len(fifa_df)
data_info = pd.DataFrame({'Column': percentage_of_missing_values_per_column.index, 'Null Percentage': percentage_of_missing_values_per_column.values})
data_info = data_info.reset_index(drop=True)
data_info_str = data_info.to_string()
print(data_info_str)

#Display the columns  with more than 30 percent missing values in a list
columns_with_over_30_percent_missing_percentage = percentage_of_missing_values_per_column[percentage_of_missing_values_per_column > 0.3]
columns_with_over_30_percent_missing_percentage = columns_with_over_30_percent_missing_percentage.index.tolist()
print(columns_with_over_30_percent_missing_percentage)

#Source: https://datascienceparichay.com/article/pandas-percentage-of-missing-values-in-each-column/

#Dropping features with more than 30 percent missing values
fifa_df = fifa_df.drop(['player_traits','goalkeeping_speed'], axis=1)
fifa_df

#This code will give  a list of the column names in the DataFrame fifa_df that have the 'object' data type.
print("object columns")
object_columns = fifa_df.select_dtypes(include=['object']).columns
print(object_columns)

#Storing the non-numeric features in a dictionary (in case of anything)
object_columns = fifa_df.select_dtypes(include=['object']).columns
print(object_columns)

#Let the object columns be stored in a new dataframe
fifa_df_object = fifa_df[object_columns]

#Dropping the "unencoded" non-numeric features from the DataFrame
fifa_df = fifa_df.drop(columns=object_columns)
fifa_df

#Encoding- Converting non-numeric features into numeric features
encoded_features = fifa_df_object.apply(lambda x: pd.factorize(x)[0])

#Source: https://www.statology.org/pandas-factorize/#:~:text=The%20pandas%20factorize%20%28%29%20function%20can%20be%20used,%3D%20pd.factorize%28df%20%5B%27col%27%5D%29%20Method%202%3A%20Factorize%20Specific%20Columns

#Concatenating the encoded features with the original DataFrame
fifa_df_encoded = pd.concat([fifa_df, encoded_features], axis=1)

fifa_df_encoded

#Imputting the data- replacing missing values
imputer=SimpleImputer(strategy='mean')
imputed = imputer.fit_transform(fifa_df_encoded)
fifa_df_imputed = pd.DataFrame(imputed, columns=fifa_df_encoded.columns)
fifa_df_imputed

"""***Feature Engineering***"""

#Storing the target feature in y
y=fifa_df_imputed['overall']

#Drop the target variable from the fifa_df_imputed dataframe
fifa_df_imputed=fifa_df_imputed.drop(columns=['overall'])

#Determine how much each independent variable corelates with the target variable, overall using correlation analysis
correlation = fifa_df_imputed.corrwith(y).abs()
sorted_correlation = correlation.sort_values(ascending=False)
sorted_correlation

#Display the columns with their correlation coefficient
correlation_df = sorted_correlation.reset_index()
correlation_df.columns = ['Feature', 'Correlation']
correlation_df

#Coefficients close to zero mean that there is no linear correlation. The decided threshold that indicates no linear correlation is 0.20.
#Setting a threshold slightly higher than 0.10 reduces the risk of including very weak correlations.
#Also, it permists the inclusion of variables with moderate correlations that might be useful in builing the model.
#Therefore, any coefficient less than 0.20 is considered to have no linear correlation with the target variable.

correlation_threshold = 0.2
columns_with_no_linear_correlation = correlation_df[correlation_df['Correlation'] <= correlation_threshold]
columns_with_no_linear_correlation

#Display the columns in a list
features_with_no_linear_correlation = columns_with_no_linear_correlation['Feature'].tolist()
features_with_no_linear_correlation

#Drop the columns with no linear correlation
fifa_df_better_correlation = fifa_df_imputed.drop([ 'pace','weight_kg', 'lcb','cb','rcb','movement_balance','work_rate','preferred_foot','height_cm','goalkeeping_positioning',
                                                    'body_type','goalkeeping_reflexes','goalkeeping_handling','goalkeeping_diving','goalkeeping_kicking'], axis=1)
fifa_df_better_correlation

# Adjust Pandas display options
pd.set_option('display.max_columns', None)
pd.set_option('display.expand_frame_repr', False)
pd.set_option('display.max_colwidth', -1)  # This is to display long text or URLs in full

print(fifa_df_better_correlation)

print("All Columns")
all_columns = fifa_df_better_correlation.columns
print(all_columns)

#Scaling the data
fifa_df_scaled=pd.DataFrame(StandardScaler().fit_transform(fifa_df_better_correlation))
fifa_df_scaled

"""***Traininig Models and Evaluation***"""

Xtrain,Xtest,Ytrain,Ytest=train_test_split(fifa_df_scaled,y,test_size=0.2,random_state=42)

#Random Forest Regressor
random_forest_model = RandomForestRegressor(n_estimators=100, random_state=42)
random_forest_scores = cross_val_score(random_forest_model, Xtrain, Ytrain, cv = 5, scoring = 'neg_mean_squared_error')     #Gives the negative mean squared error
rmse = -random_forest_scores.mean()
print(rmse**0.5)

random_forest_model.fit(Xtrain, Ytrain)
score = random_forest_model.score(Xtest, Ytest)        #Gives the accurcay of the model
print(score)

#The accuarcy of the model was approximately 99 percent the first time so fine-tuning was not needed.

#XGBoost Regressor
xgboost_model = XGBRegressor(objective ='reg:squarederror', random_state=42)         #The objective is trying to minimise the sqaured error
xgb_scores = cross_val_score(xgboost_model, Xtrain, Ytrain, cv = 5, scoring = 'neg_mean_squared_error')     #Gives the negative mean squared error
rmse = -xgb_scores.mean()
print(rmse**0.5)

xgboost_model.fit(Xtrain, Ytrain)
score = xgboost_model.score(Xtest, Ytest)        #Gives the accurcay of the model
print(score)

#The accuarcy of the model was approximately 99 percent the first time so fine-tuning was not needed.

#Gradient Regressor
gb_model = GradientBoostingRegressor(n_estimators= 500, random_state=42, max_depth= 5, min_samples_split =2, learning_rate =0.01)      #Increasing the number of estimators, adding max depth, min samples split and learning rate was a way of optimizing my model
gb_scores = cross_val_score(gb_model, Xtrain, Ytrain, cv = 5, scoring = 'neg_mean_squared_error')     #Gives the negative mean squared error
rmse = -gb_scores.mean()
print(rmse**0.5)

gb_model.fit(Xtrain, Ytrain)
score = gb_model.score(Xtest, Ytest)        #Gives the accurcay of the model
print(score)

"""***Ensemble Learning***"""

#Soft-Voting
#Voting regressor is my model
voting_regressor = VotingRegressor(estimators=[
    ('random forest', random_forest_model),
    ('xg boost', xgboost_model),
    ('gradient boost', gb_model)])

for model in (random_forest_model, xgboost_model, gb_model,voting_regressor):
  model.fit(Xtrain,Ytrain)
  y_pred=model.predict(Xtest)
  score = model.score(Xtest, Ytest)
  mse = mean_squared_error(Ytest, y_pred)

print(score)
print(mse)

#The accuarcy of the ensembled model was approximately 99 percent the first time so fine-tuning was not needed.

"""***Test with new data set***

***Cleaning the new data set***
"""

#The name of my dataframe is 'fifa_22_df'.
fifa_22_df = pd.read_csv('/content/drive/My Drive/Introduction_to_AI_Mid_Semester_Project/players_22.csv')
fifa_22_df.info()
fifa_22_df.describe()
fifa_22_df.head()

#Dropping features that cannot predicate a player's overall rating
#Store them in a variable first
useless_features_22 = [
       'player_url', 'short_name', 'long_name', 'player_positions', 'dob', 'league_name', 'club_position', 'club_loaned_from',
       'club_joined', 'nationality_name', 'nation_position', 'real_face', 'player_tags','player_face_url', 'club_logo_url',
       'club_flag_url', 'nation_logo_url', 'nation_flag_url', 'sofifa_id',  'nationality_id','club_team_id','club_jersey_number',
       'club_contract_valid_until', 'nation_team_id',
       'nation_jersey_number', 'release_clause_eur']

useless_features_dataframe_22 = fifa_22_df[useless_features_22].copy()

fifa_22_df = fifa_22_df.drop(['player_url', 'short_name', 'long_name', 'player_positions', 'dob', 'league_name', 'club_position', 'club_loaned_from',
       'club_joined', 'nationality_name', 'nation_position', 'real_face', 'player_tags','player_face_url', 'club_logo_url',
       'club_flag_url', 'nation_logo_url', 'nation_flag_url', 'sofifa_id',  'nationality_id','club_team_id','club_jersey_number',
       'club_contract_valid_until', 'nation_team_id',
       'nation_jersey_number', 'release_clause_eur'], axis=1)

#Finding the percentage of missing values in each column
percentage_of_missing_values_per_column_22= fifa_22_df.isnull().sum()/len(fifa_22_df)
data_info_22 = pd.DataFrame({'Column': percentage_of_missing_values_per_column_22.index, 'Null Percentage': percentage_of_missing_values_per_column.values})
data_info_22 = data_info_22.reset_index(drop=True)
data_info_str = data_info_22.to_string()
print(data_info_str)

#Display the columns  with more than 30 percent missing values in a list
columns_with_over_30_percent_missing_percentage_22 = percentage_of_missing_values_per_column_22[percentage_of_missing_values_per_column_22 > 0.3]
columns_with_over_30_percent_missing_percentage_22 = columns_with_over_30_percent_missing_percentage_22.index.tolist()
print(columns_with_over_30_percent_missing_percentage_22)

#Source: https://datascienceparichay.com/article/pandas-percentage-of-missing-values-in-each-column/

#Dropping features with more than 30 percent missing values
fifa_22_df = fifa_22_df.drop(['player_traits','goalkeeping_speed'], axis=1)
fifa_22_df

#This code will give a list of the column names in DataFrame fifa_df_22 that have the 'object' data type.
print("object columns 22")
object_columns_22 = fifa_22_df.select_dtypes(include=['object']).columns
print(object_columns_22)

#Storing the non-numeric features in a dictionary (in case of anything)
object_columns_22 = fifa_22_df.select_dtypes(include=['object']).columns
print(object_columns_22)

#Let the object columns be stored in a new dataframe
fifa_df_object_22 = fifa_22_df[object_columns_22]

#Dropping the "unencoded" non-numeric features from the DataFrame
fifa_22_df = fifa_22_df.drop(columns=object_columns_22)
fifa_22_df

#Encoding- Converting non-numeric features into numeric features
encoded_features_22 = fifa_df_object_22.apply(lambda x: pd.factorize(x)[0])

#Source: https://www.statology.org/pandas-factorize/#:~:text=The%20pandas%20factorize%20%28%29%20function%20can%20be%20used,%3D%20pd.factorize%28df%20%5B%27col%27%5D%29%20Method%202%3A%20Factorize%20Specific%20Columns

#Concatenating the encoded features with the original DataFrame
fifa_df_encoded_22 = pd.concat([fifa_22_df, encoded_features_22], axis=1)

#Imputting the data- replacing missing values
imputer=SimpleImputer(strategy='mean')
imputed = imputer.fit_transform(fifa_df_encoded_22)
fifa_df_imputed_22 = pd.DataFrame(imputed, columns=fifa_df_encoded_22.columns)
fifa_df_imputed_22

#Storing the target feature in y
y_22=fifa_df_imputed_22['overall']

#Drop the target variable from the fifa_df_imputed dataframe
fifa_df_imputed_22=fifa_df_imputed_22.drop(columns=['overall'])

fifa_df_imputed_22

#Dropped the columns that were dropped correlation analysis
fifa_df_imputed_22 = fifa_df_imputed_22.drop([ 'pace','weight_kg', 'lcb','cb','rcb','movement_balance','work_rate','preferred_foot','height_cm','goalkeeping_positioning',
                                                    'body_type','goalkeeping_reflexes','goalkeeping_handling','goalkeeping_diving','goalkeeping_kicking'], axis=1)
fifa_df_imputed_22

#Scaling the data
fifa_df_scaled_22=pd.DataFrame(StandardScaler().fit_transform(fifa_df_imputed_22))
fifa_df_scaled_22

"""***Testing***"""

#Training the ensembled model
#We are giving the model new data and comparing the actual data to the predicted data
y_pred_22=voting_regressor.predict(fifa_df_scaled_22)
score = voting_regressor.score(fifa_df_scaled_22, y_22)
mse_22 = mean_squared_error(y_22, y_pred_22)
print(score)
print(mse_22)

#The accuarcy of the ensembled model was approximately 99 percent  the first time so fine-tuning was not needed.

"""***Deployment***"""

# pickling the model
pickle_out = open('/content/drive/My Drive/Introduction_to_AI_Mid_Semester_Project/voting_regressor.pkl', 'wb')
pickle.dump(voting_regressor, pickle_out)
pickle_out.close()